import torch
import numpy as np
from PIL import Image, ImageOps, ImageFilter, ImageEnhance
from nodes import MAX_RESOLUTION
from .utils import get_current_language, build_types,get_localized_tooltips
from .yiu_base_node import YiuBaseNode

print('this is yiu_img_cnv_placer.py - 202507051718')

class yiuImgCnvPlacer(YiuBaseNode):    
    tooltips_dict={
        "zh-CN":{ 
            "input":{
                "image": "éœ€è¦æ‰©å›¾çš„å›¾ç‰‡",
                "mask": "éœ€è¦æ‰©å›¾å›¾ç‰‡ä¸Šç»˜åˆ¶çš„è’™ç‰ˆ",
                "resolution": "SDXLä¸FLUXåˆ†è¾¨ç‡ï¼Œç”¨ä½œè¾“å‡ºå›¾ç‰‡çš„ç”»æ¿å°ºå¯¸",
                "width_overwrite": "å®½åº¦è¦†ç›–ï¼Œå½“ä½¿ç”¨éä¸Šè¿°åˆ†è¾¨ç‡æ—¶ï¼Œå°†è¦†ç›–åˆ†è¾¨ç‡çš„å®½åº¦ã€‚",
                "height_overwrite": "é«˜åº¦è¦†ç›–ï¼Œå½“ä½¿ç”¨éä¸Šè¿°åˆ†è¾¨ç‡æ—¶ï¼Œå°†è¦†ç›–åˆ†è¾¨ç‡çš„é«˜åº¦ã€‚",
                "x_pos": "Xè½´ä½ç½®ï¼Œå›¾ç‰‡åœ¨ç”»æ¿çš„æœ€å·¦è¾¹è¿˜æ˜¯æœ€å³è¾¹",
                "y_pos": "Yè½´ä½ç½®ï¼Œå›¾ç‰‡åœ¨ç”»æ¿çš„æœ€ä¸Šè¾¹è¿˜æ˜¯æœ€ä¸‹è¾¹",
                "scale": "ç¼©æ”¾ï¼Œå›¾ç‰‡ç›¸å¯¹ç”»æ¿çš„å æ¯”",
                "feather_radius": "ç¾½åŒ–åŠå¾„ï¼Œæ‰©å›¾æ—¶ç¾½åŒ–çš„èŒƒå›´",
            },
            "output":{
                "image": "å·²ç»æ”¾åœ¨æ‰©å±•ç”»æ¿ä¸­çš„å›¾åƒ",
                "original_mask": "å·²ç»æ”¾åœ¨æ‰©å±•ç”»æ¿ä¸­çš„åŸæ¥çš„é®ç½©",
                "expand_mask": "æ‰©å›¾èŠ‚ç‚¹éœ€è¦çš„æ‰©å±•é®ç½©",
                "help_text": "å¸®åŠ©ä¿¡æ¯",
            }
        },
        "en":{
            "input": {
                "image": "Image to be expanded",
                "mask": "Mask to be drawn on the image to be expanded",
                "resolution": "SDXL and FLUX resolution, used as the canvas size for output images",
                "width_overwrite": "Width override, when using a resolution other than the ones above, will override the width of the resolution.",
                "height_overwrite": "Height override, when using a resolution other than the above, will override the resolution's height.",
                "x_pos": "X-axis position, is the image on the left or right of the canvas",
                "y_pos": "Y-axis position, is the image on the top or bottom of the canvas",
                "scale": "Scale, the proportion of the image relative to the canvas",
                "feather_radius": "Feather radius, the range of feathering when expanding the image",
            },
            "output":{
                "image": "The image already placed in the extended artboard",
                "original_mask": "The original mask already placed in the extended artboard",
                "expand_mask": "The expanded mask required by the expansion node",
                "help_text": "Help Text",
            }
        }
    }


    base_inputs = {
                "image": ("IMAGE",{}),
                "mask": ("MASK",{"default": None}),
                "resolution": (
                    [
                        "1600x1024",
                        "1536x1536",
                        "1536x1024",
                        "1344x768",
                        "1280x768",
                        "1152x896",
                        "1152x768",
                        "1104x832",
                        "1024x1600",
                        "1024x1536",
                        "1024x1344",
                        "1024x1280",
                        "1024x1152",
                        "1024x1024",
                        "960x1344",
                        "896x1536",
                        "896x1152",
                        "896x768",
                        "832x1104",
                        "768x1536",
                        "768x1280",
                        "768x1152",
                        "768x1024",
                        "768x896"
                    ],
                    {"default": "1024x1024","unit":"px"}
                ),

                "width_overwrite": ("INT", {"default": 0, "min": 0,"unit":"px"}),
                "height_overwrite": ("INT", {"default": 0, "min": 0,"unit":"px"}),
                "x_pos": ("FLOAT", {"display": "slider", "default": 50, "min": 0.0, "max": 100.0,"unit":"%"}),
                "y_pos": ("FLOAT", {"display": "slider", "default": 50, "min": 0.0, "max": 100.0,"unit":"%"}),
          
                "scale": ("FLOAT", {"display": "slider", "default":100, "min": 1, "max": 100, "step": 0.1 ,"unit":"%"}),
                "feather_radius": ("INT", {"default": 20, "min": 0, "max": MAX_RESOLUTION, "step": 1 ,"unit":"px"}),
            }
    
    base_outputs = {
            "image": "IMAGE",
            "original_mask": "MASK",
            "expand_mask": "MASK",
            "help_text": "STRING"
        }
    
  


    MAIN='better_image_pad_for_outpainting'



    @classmethod
    def DISPLAY_NAME(cls):
        return "ğŸ–Šï¸ Yiu Image Canvas Placer"
    
    @classmethod
    def get_help_text(self):
        lang = get_current_language()
        help_texts = {
            "zh-CN": '''ğŸ“– ä½¿ç”¨è¯´æ˜ï¼šå°†è¾“å…¥çš„image ã€ maskï¼Œæ ¹æ®x_posï¼ˆæ°´å¹³æ–¹å‘çš„ä½ç½®ï¼‰ã€y_posï¼ˆå‚ç›´æ–¹å‘çš„ä½ç½®ï¼‰ã€scaleï¼ˆåœ¨ç”»æ¿ä¸­çš„å æ¯”ï¼‰ï¼Œæ”¾ç½®åœ¨ resolutionï¼ˆç”»å¸ƒåˆ†è¾¨ç‡ï¼‰å¤§å°çš„ç”»æ¿ä¸­ã€‚
            è¾“å…¥çš„imageå»ºè®®å…ˆç»è¿‡æŠ å›¾èŠ‚ç‚¹å¤„ç†ã€‚
            è¾“å‡ºçš„image å’Œ expand_mask å¯ç­‰æ•ˆäºâ€œå¤–è¡¥ç”»æ¿â€ï¼Œæ¥åˆ°æ‰©å›¾å·¥ä½œæµä¸­ã€‚
            è¾“å‡ºçš„ original_mask ä¸ºå¯¹åº”ç¼©æ”¾ç§»åŠ¨çš„è¾“å…¥çš„maskï¼Œå¯å¯¹åº”æ¥åˆ°Lamaï¼Œæˆ–è€…æ¥åˆ°æˆ‘çš„ yiu_fit_itm_2_msk èŠ‚ç‚¹çš„ camvas_mask ã€‚''',
            "en": "ğŸ“– Recommended to cut out the product image first. Mask decides product placement."
        }
        return get_localized_tooltips(self.tooltips_dict,lang)+'\n'+help_texts.get(lang, help_texts["en"])
    
    @classmethod
    def adjust_levels(self, image, black=0, white=1, gamma=1.0):
        """è°ƒæ•´å›¾åƒè‰²é˜¶ï¼Œç±»ä¼¼Photoshopçš„è‰²é˜¶åŠŸèƒ½"""
        # å°†å›¾åƒè½¬æ¢ä¸ºnumpyæ•°ç»„
        arr = np.array(image, dtype=np.float32) / 255.0
        
        # åº”ç”¨è‰²é˜¶è°ƒæ•´
        arr = np.clip((arr - black) / (white - black), 0, 1)
        arr = np.power(arr, gamma)
        
        # è½¬æ¢å›PILå›¾åƒ
        return Image.fromarray((arr * 255).astype(np.uint8))
    
    @classmethod
    def better_image_pad_for_outpainting(self, image, mask=None, resolution="1024x1024", width_overwrite=0, height_overwrite=0, x_pos=50, y_pos=50, scale=100, feather_radius=20):        
        # è§£æ SDXL åˆ†è¾¨ç‡
        try:
            sdxl_width, sdxl_height = map(int, resolution.split("x"))
        except ValueError:
            raise ValueError(f"Invalid SDXL resolution format: {resolution}")

        width = width_overwrite if width_overwrite != 0 else sdxl_width
        height = height_overwrite if height_overwrite != 0 else sdxl_height

        # å¤„ç†å›¾åƒ
        batch_size, img_h, img_w, channels = image.shape
        image_np = image[0].cpu().numpy() * 255.0
        image_np = image_np.astype(np.uint8)
        
        # è½¬æ¢ä¸ºRGBAæ ¼å¼ä»¥æ”¯æŒé€æ˜
        if channels == 3:
            pil_image = Image.fromarray(image_np).convert("RGBA")
        else:
            pil_image = Image.fromarray(image_np)

        expanded_width = width
        expanded_height = height
        new_width,new_height =  map(int, self.scale_rect(img_w, img_h, expanded_width, expanded_height, scale))

        # ç¼©å°å›¾åƒ
        resized_image = pil_image.resize((new_width, new_height), Image.LANCZOS)

        x = int(x_pos / 100 * (expanded_width - new_width))
        y = int(y_pos / 100 * (expanded_height - new_height))
        
        print("x:", x, "y:", y)
        print("new_width:", new_width, "new_height:", new_height)
        print("expanded_width:", expanded_width, "expanded_height:", expanded_height)


        
        # åˆ›å»ºé€æ˜èƒŒæ™¯çš„æ–°å›¾åƒ
        expanded_image = Image.new("RGBA", (expanded_width, expanded_height), (0, 0, 0, 0))
        
        # å°†ç¼©å°åçš„å›¾åƒç²˜è´´åˆ°ä¸­å¿ƒ
        paste_position = (x, y)

        expanded_image.paste(resized_image, paste_position)
        
        # åˆ›å»ºæ‰©å±•åŒºåŸŸçš„è’™ç‰ˆ
        expand_mask = Image.new("L", (expanded_width, expanded_height), 0)
        
        # åˆ›å»ºä¸­å¿ƒåŒºåŸŸï¼ˆéæ‰©å±•åŒºåŸŸï¼‰çš„çŸ©å½¢
        img_box = (
            x, 
            y, 
            x + new_width, 
            y + new_height
        )
        
        # åœ¨æ‰©å±•è’™ç‰ˆä¸Šç»˜åˆ¶ç™½è‰²çŸ©å½¢ï¼ˆä¸­å¿ƒåŒºåŸŸï¼‰
        draw = Image.new("L", (new_width, new_height), 255)
        expand_mask.paste(draw, img_box)
        
        # åè½¬è’™ç‰ˆå¾—åˆ°æ‰©å±•åŒºåŸŸè’™ç‰ˆ
        expand_mask = ImageOps.invert(expand_mask)
        
        # åº”ç”¨ç¾½åŒ–æ•ˆæœ
        if feather_radius > 0:
            # å…ˆåº”ç”¨ä¸¤å€æ¨¡ç³Šé‡
            expand_mask = expand_mask.filter(ImageFilter.GaussianBlur(feather_radius * 2))
            
            # ä½¿ç”¨è‰²é˜¶è°ƒæ•´ï¼šå°†0.5ç°è‰²å˜ä¸º1ç™½è‰²ï¼Œ0é»‘è‰²ä¿æŒä¸å˜
            expand_mask = self.adjust_levels(expand_mask, black=0, white=0.5, gamma=1.0)
        
        # å°†PILå›¾åƒè½¬æ¢å›å¼ é‡
        expanded_image_np = np.array(expanded_image).astype(np.float32) / 255.0
        expanded_image_tensor = torch.from_numpy(expanded_image_np).unsqueeze(0)
        
        # å¤„ç†åŸå§‹è’™ç‰ˆï¼ˆå¦‚æœæœ‰ï¼‰
        original_mask_tensor = None
        if mask is not None:
            # å°†è’™ç‰ˆå¼ é‡è½¬æ¢ä¸ºPILå›¾åƒ
            mask_np = mask[0].cpu().numpy() * 255.0
            mask_np = mask_np.astype(np.uint8)
            pil_mask = Image.fromarray(mask_np)
            
            # ç¼©å°è’™ç‰ˆ
            resized_mask = pil_mask.resize((new_width, new_height), Image.LANCZOS)
            
            # åˆ›å»ºæ–°è’™ç‰ˆï¼ˆé»‘è‰²èƒŒæ™¯ï¼‰
            expanded_original_mask = Image.new("L", (expanded_width, expanded_height), 0)
            
            # å°†ç¼©å°åçš„è’™ç‰ˆç²˜è´´åˆ°ä¸­å¿ƒ
            expanded_original_mask.paste(resized_mask, paste_position)
            
            # å°†PILè’™ç‰ˆè½¬æ¢å›å¼ é‡
            expanded_original_mask_np = np.array(expanded_original_mask).astype(np.float32) / 255.0
            original_mask_tensor = torch.from_numpy(expanded_original_mask_np).unsqueeze(0)
        
        # å°†æ‰©å±•è’™ç‰ˆè½¬æ¢ä¸ºå¼ é‡
        expand_mask_np = np.array(expand_mask).astype(np.float32) / 255.0
        expand_mask_tensor = torch.from_numpy(expand_mask_np).unsqueeze(0)
        
        # å¦‚æœè¾“å…¥æ˜¯æ‰¹é‡å¤„ç†ï¼Œå¤åˆ¶ç»“æœä»¥åŒ¹é…æ‰¹é‡å¤§å°
        if batch_size > 1:
            expanded_image_tensor = expanded_image_tensor.repeat(batch_size, 1, 1, 1)
            expand_mask_tensor = expand_mask_tensor.repeat(batch_size, 1, 1)
            if original_mask_tensor is not None:
                original_mask_tensor = original_mask_tensor.repeat(batch_size, 1, 1)
        
        # è¿”å›ç»“æœï¼Œå¦‚æœæ²¡æœ‰åŸå§‹è’™ç‰ˆåˆ™è¿”å›å…¨é›¶è’™ç‰ˆ
        if original_mask_tensor is not None:
            return (expanded_image_tensor, original_mask_tensor, expand_mask_tensor,)
        else:
            empty_mask = torch.zeros((batch_size, expanded_height, expanded_width))
            return (expanded_image_tensor, empty_mask, expand_mask_tensor,)


    @classmethod
    def scale_rect(self, width, height, container_width, container_height, scale):
        """è®¡ç®—ç¼©æ”¾åçš„çŸ©å½¢å°ºå¯¸"""
        if scale == 0:
            return (0, 0)
        scale_factor = scale / 100
        if scale == 100:
            scale_factor = min(container_width / width, container_height / height)
        return (width * scale_factor, height * scale_factor)
    
