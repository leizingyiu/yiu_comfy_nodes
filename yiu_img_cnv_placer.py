import torch
import numpy as np
from PIL import Image, ImageOps, ImageFilter, ImageEnhance
from nodes import MAX_RESOLUTION

class yiuImgCnvPlacer:    
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "image": ("IMAGE",),
                "sdxl_resolution": (
                    [
                        "1024x1024",
                        "1152x896",
                        "896x1152",
                        "1216x832",
                        "832x1216",
                        "1344x768",
                        "768x1344",
                        "1536x640",
                        "640x1536"
                    ],
                    {"default": "1024x1024"}
                ),

                "width_overwrite": ("INT", {"default": 0, "min": 0}),
                "height_overwrite": ("INT", {"default": 0, "min": 0}),
                "x_pos": ("FLOAT", {"display": "slider", "default": 50, "min": 0.0, "max": 100.0}),
                "y_pos": ("FLOAT", {"display": "slider", "default": 50, "min": 0.0, "max": 100.0}),
          
                "scale": ("FLOAT", {"display": "slider", "default":100, "min": 1, "max": 100, "step": 0.1}),
                "feather_radius": ("INT", {"default": 20, "min": 0, "max": MAX_RESOLUTION, "step": 1}),
            },
            "optional": {
                "mask": ("MASK",),
            }
        }
    
    RETURN_TYPES = ("IMAGE", "MASK", "MASK",)
    RETURN_NAMES = ("image", "original_mask", "expand_mask",)
    FUNCTION = "better_image_pad_for_outpainting"
    CATEGORY = "yiu_nodes"
    
    @classmethod
    def DISPLAY_NAME(cls):
        return "ğŸ–Šï¸ Yiu Image Canvas Placer"
    
    def adjust_levels(self, image, black=0, white=1, gamma=1.0):
        """è°ƒæ•´å›¾åƒè‰²é˜¶ï¼Œç±»ä¼¼Photoshopçš„è‰²é˜¶åŠŸèƒ½"""
        # å°†å›¾åƒè½¬æ¢ä¸ºnumpyæ•°ç»„
        arr = np.array(image, dtype=np.float32) / 255.0
        
        # åº”ç”¨è‰²é˜¶è°ƒæ•´
        arr = np.clip((arr - black) / (white - black), 0, 1)
        arr = np.power(arr, gamma)
        
        # è½¬æ¢å›PILå›¾åƒ
        return Image.fromarray((arr * 255).astype(np.uint8))
    
    def better_image_pad_for_outpainting(self, image, mask=None, sdxl_resolution="1024x1024", width_overwrite=0, height_overwrite=0, x_pos=50, y_pos=50, scale=100, feather_radius=20):        
        # è§£æ SDXL åˆ†è¾¨ç‡
        if width_overwrite == 0 or height_overwrite == 0:
            try:
                sdxl_width, sdxl_height = map(int, sdxl_resolution.split("x"))
            except ValueError:
                raise ValueError(f"Invalid SDXL resolution format: {sdxl_resolution}")
            width = sdxl_width
            height = sdxl_height
        else:
            width = width_overwrite
            height = height_overwrite

        # å¤„ç†å›¾åƒ
        batch_size, img_h, img_w, channels = image.shape
        image_np = image[0].cpu().numpy() * 255.0
        image_np = image_np.astype(np.uint8)
        
        # è½¬æ¢ä¸ºRGBAæ ¼å¼ä»¥æ”¯æŒé€æ˜
        if channels == 3:
            pil_image = Image.fromarray(image_np).convert("RGBA")
        else:
            pil_image = Image.fromarray(image_np)

        expanded_width = width
        expanded_height = height
        new_width,new_height =  map(int, self.scale_rect(img_w, img_h, expanded_width, expanded_height, scale))

        # ç¼©å°å›¾åƒ
        resized_image = pil_image.resize((new_width, new_height), Image.LANCZOS)

        x = int(x_pos / 100 * (expanded_width - new_width))
        y = int(y_pos / 100 * (expanded_height - new_height))
        
        print("x:", x, "y:", y)
        print("new_width:", new_width, "new_height:", new_height)
        print("expanded_width:", expanded_width, "expanded_height:", expanded_height)


        
        # åˆ›å»ºé€æ˜èƒŒæ™¯çš„æ–°å›¾åƒ
        expanded_image = Image.new("RGBA", (expanded_width, expanded_height), (0, 0, 0, 0))
        
        # å°†ç¼©å°åçš„å›¾åƒç²˜è´´åˆ°ä¸­å¿ƒ
        paste_position = (x, y)

        expanded_image.paste(resized_image, paste_position)
        
        # åˆ›å»ºæ‰©å±•åŒºåŸŸçš„è’™ç‰ˆ
        expand_mask = Image.new("L", (expanded_width, expanded_height), 0)
        
        # åˆ›å»ºä¸­å¿ƒåŒºåŸŸï¼ˆéæ‰©å±•åŒºåŸŸï¼‰çš„çŸ©å½¢
        img_box = (
            x, 
            y, 
            x + new_width, 
            y + new_height
        )
        
        # åœ¨æ‰©å±•è’™ç‰ˆä¸Šç»˜åˆ¶ç™½è‰²çŸ©å½¢ï¼ˆä¸­å¿ƒåŒºåŸŸï¼‰
        draw = Image.new("L", (new_width, new_height), 255)
        expand_mask.paste(draw, img_box)
        
        # åè½¬è’™ç‰ˆå¾—åˆ°æ‰©å±•åŒºåŸŸè’™ç‰ˆ
        expand_mask = ImageOps.invert(expand_mask)
        
        # åº”ç”¨ç¾½åŒ–æ•ˆæœ
        if feather_radius > 0:
            # å…ˆåº”ç”¨ä¸¤å€æ¨¡ç³Šé‡
            expand_mask = expand_mask.filter(ImageFilter.GaussianBlur(feather_radius * 2))
            
            # ä½¿ç”¨è‰²é˜¶è°ƒæ•´ï¼šå°†0.5ç°è‰²å˜ä¸º1ç™½è‰²ï¼Œ0é»‘è‰²ä¿æŒä¸å˜
            expand_mask = self.adjust_levels(expand_mask, black=0, white=0.5, gamma=1.0)
        
        # å°†PILå›¾åƒè½¬æ¢å›å¼ é‡
        expanded_image_np = np.array(expanded_image).astype(np.float32) / 255.0
        expanded_image_tensor = torch.from_numpy(expanded_image_np).unsqueeze(0)
        
        # å¤„ç†åŸå§‹è’™ç‰ˆï¼ˆå¦‚æœæœ‰ï¼‰
        original_mask_tensor = None
        if mask is not None:
            # å°†è’™ç‰ˆå¼ é‡è½¬æ¢ä¸ºPILå›¾åƒ
            mask_np = mask[0].cpu().numpy() * 255.0
            mask_np = mask_np.astype(np.uint8)
            pil_mask = Image.fromarray(mask_np)
            
            # ç¼©å°è’™ç‰ˆ
            resized_mask = pil_mask.resize((new_width, new_height), Image.LANCZOS)
            
            # åˆ›å»ºæ–°è’™ç‰ˆï¼ˆé»‘è‰²èƒŒæ™¯ï¼‰
            expanded_original_mask = Image.new("L", (expanded_width, expanded_height), 0)
            
            # å°†ç¼©å°åçš„è’™ç‰ˆç²˜è´´åˆ°ä¸­å¿ƒ
            expanded_original_mask.paste(resized_mask, paste_position)
            
            # å°†PILè’™ç‰ˆè½¬æ¢å›å¼ é‡
            expanded_original_mask_np = np.array(expanded_original_mask).astype(np.float32) / 255.0
            original_mask_tensor = torch.from_numpy(expanded_original_mask_np).unsqueeze(0)
        
        # å°†æ‰©å±•è’™ç‰ˆè½¬æ¢ä¸ºå¼ é‡
        expand_mask_np = np.array(expand_mask).astype(np.float32) / 255.0
        expand_mask_tensor = torch.from_numpy(expand_mask_np).unsqueeze(0)
        
        # å¦‚æœè¾“å…¥æ˜¯æ‰¹é‡å¤„ç†ï¼Œå¤åˆ¶ç»“æœä»¥åŒ¹é…æ‰¹é‡å¤§å°
        if batch_size > 1:
            expanded_image_tensor = expanded_image_tensor.repeat(batch_size, 1, 1, 1)
            expand_mask_tensor = expand_mask_tensor.repeat(batch_size, 1, 1)
            if original_mask_tensor is not None:
                original_mask_tensor = original_mask_tensor.repeat(batch_size, 1, 1)
        
        # è¿”å›ç»“æœï¼Œå¦‚æœæ²¡æœ‰åŸå§‹è’™ç‰ˆåˆ™è¿”å›å…¨é›¶è’™ç‰ˆ
        if original_mask_tensor is not None:
            return (expanded_image_tensor, original_mask_tensor, expand_mask_tensor,)
        else:
            empty_mask = torch.zeros((batch_size, expanded_height, expanded_width))
            return (expanded_image_tensor, empty_mask, expand_mask_tensor,)

    def scale_rect(self, width, height, container_width, container_height, scale):
        """è®¡ç®—ç¼©æ”¾åçš„çŸ©å½¢å°ºå¯¸"""
        if scale == 0:
            return (0, 0)
        scale_factor = scale / 100
        if scale == 100:
            scale_factor = min(container_width / width, container_height / height)
        return (width * scale_factor, height * scale_factor)